{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Yolov5.ipynb","provenance":[],"mount_file_id":"1oHvL0vo3P4QzXSJ0Zkg6H11WFXYv0s64","authorship_tag":"ABX9TyNrsG4WnxuDD6UourPWlDqf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AtFU3SbjdPiT","executionInfo":{"status":"ok","timestamp":1646800887313,"user_tz":-420,"elapsed":416,"user":{"displayName":"Tinh Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIkEDM4mLNp9aMlnCQpNdWzDQ15k_zUJE6hLYtLw=s64","userId":"07458451242153991254"}},"outputId":"39e3591d-f3cd-4079-de3e-92f36ac060d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/VienAI/Yolov5\n"]}],"source":["%cd /content/drive/MyDrive/VienAI/Yolov5"]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qQq4PcZyiU5D","executionInfo":{"status":"ok","timestamp":1646793416052,"user_tz":-420,"elapsed":610,"user":{"displayName":"Tinh Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIkEDM4mLNp9aMlnCQpNdWzDQ15k_zUJE6hLYtLw=s64","userId":"07458451242153991254"}},"outputId":"6c908aeb-2d6e-467b-f7bb-128937432731"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;36mFace-SPARNet\u001b[0m@             train_yolox_VOC.ipynb  \u001b[01;34mYolov5\u001b[0m/\n","RoadDamageDetector.ipynb  \u001b[01;34mYolov4\u001b[0m/                \u001b[01;34mYOLOX\u001b[0m/\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/ultralytics/yolov5  # clone"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CIYMjCIXg5rk","executionInfo":{"status":"ok","timestamp":1646793439407,"user_tz":-420,"elapsed":6088,"user":{"displayName":"Tinh Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIkEDM4mLNp9aMlnCQpNdWzDQ15k_zUJE6hLYtLw=s64","userId":"07458451242153991254"}},"outputId":"23692c9a-0f53-42d4-c3b3-6dcf3fe33972"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 11212, done.\u001b[K\n","remote: Total 11212 (delta 0), reused 0 (delta 0), pack-reused 11212\u001b[K\n","Receiving objects: 100% (11212/11212), 11.16 MiB | 6.96 MiB/s, done.\n","Resolving deltas: 100% (7753/7753), done.\n"]}]},{"cell_type":"code","source":["%cd yolov5\n","!pip install -r requirements.txt  # install"],"metadata":{"id":"-QjbEhDVg5t5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install wandb"],"metadata":{"id":"qEPvZPR9_j2O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/datasets/coco128\n","!curl -L \"https://drive.google.com/u/0/uc?id=1xwCCDSdbltnRRq5TVK3AlnR_J3eSGnw8&export=download&confirm=t\" > data.zip; unzip data.zip"],"metadata":{"id":"7MEHIEeV05xC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/VienAI/Yolov5/yolov5\n","!python train.py --img 640 --batch 64 --epochs 10 --data /content/drive/MyDrive/VienAI/Yolov5/datasets/coco128/data.yaml --weights yolov5s.pt --device 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"spd_wx6Lg5wM","executionInfo":{"status":"ok","timestamp":1646806489611,"user_tz":-420,"elapsed":5016797,"user":{"displayName":"Tinh Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIkEDM4mLNp9aMlnCQpNdWzDQ15k_zUJE6hLYtLw=s64","userId":"07458451242153991254"}},"outputId":"dff902ba-5d2b-48f6-8109-57fd0a90a17d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/VienAI/Yolov5/yolov5\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/drive/MyDrive/VienAI/Yolov5/datasets/coco128/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n","YOLOv5 ðŸš€ v6.1-21-ge6e36aa torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Overriding model.yaml nc=80 with nc=9\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     37758  models.yolo.Detect                      [9, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model Summary: 270 layers, 7043902 parameters, 7043902 gradients, 15.9 GFLOPs\n","\n","Transferred 343/349 items from yolov5s.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/datasets/coco128/train/labels.cache' images and labels... 6335 found, 0 missing, 0 empty, 0 corrupt: 100% 6335/6335 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/datasets/coco128/valid/labels.cache' images and labels... 1811 found, 0 missing, 0 empty, 0 corrupt: 100% 1811/1811 [00:00<?, ?it/s]\n","Plotting labels to runs/train/exp3/labels.jpg... \n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.94 anchors/target, 0.990 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp3\u001b[0m\n","Starting training for 10 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       0/9     11.3G   0.07571   0.03052   0.05148       190       640: 100% 99/99 [07:30<00:00,  4.55s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:46<00:00,  3.13s/it]\n","                 all       1811       3025      0.631      0.177      0.107     0.0272\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       1/9     11.1G   0.05829   0.02427   0.03196       192       640: 100% 99/99 [07:25<00:00,  4.50s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:43<00:00,  2.91s/it]\n","                 all       1811       3025      0.641      0.271       0.19     0.0626\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       2/9     11.1G   0.05232   0.02293   0.02619       176       640: 100% 99/99 [07:25<00:00,  4.50s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:42<00:00,  2.84s/it]\n","                 all       1811       3025       0.45      0.292      0.224      0.075\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       3/9     11.1G   0.04884   0.02316   0.02377       202       640: 100% 99/99 [07:24<00:00,  4.49s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:42<00:00,  2.81s/it]\n","                 all       1811       3025      0.549      0.366      0.334      0.133\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       4/9     11.1G   0.04701   0.02241   0.02225       189       640: 100% 99/99 [07:26<00:00,  4.51s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.73s/it]\n","                 all       1811       3025      0.677      0.375      0.368      0.163\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       5/9     11.1G   0.04541   0.02216   0.02128       189       640: 100% 99/99 [07:25<00:00,  4.50s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:41<00:00,  2.76s/it]\n","                 all       1811       3025      0.579      0.413      0.379      0.179\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       6/9     11.1G   0.04342   0.02191   0.01983       187       640: 100% 99/99 [07:27<00:00,  4.52s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:41<00:00,  2.73s/it]\n","                 all       1811       3025      0.601      0.411      0.416      0.197\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       7/9     11.1G   0.04212   0.02163   0.01858       181       640: 100% 99/99 [07:24<00:00,  4.49s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.71s/it]\n","                 all       1811       3025      0.557      0.436      0.434      0.212\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       8/9     11.1G   0.04113   0.02134   0.01736       161       640: 100% 99/99 [07:25<00:00,  4.50s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.72s/it]\n","                 all       1811       3025      0.571      0.435      0.449      0.223\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       9/9     11.1G   0.03964   0.02093   0.01642       206       640: 100% 99/99 [07:25<00:00,  4.50s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.71s/it]\n","                 all       1811       3025       0.64      0.463      0.477      0.245\n","\n","10 epochs completed in 1.360 hours.\n","Optimizer stripped from runs/train/exp3/weights/last.pt, 14.5MB\n","Optimizer stripped from runs/train/exp3/weights/best.pt, 14.5MB\n","\n","Validating runs/train/exp3/weights/best.pt...\n","Fusing layers... \n","Model Summary: 213 layers, 7034398 parameters, 0 gradients, 15.9 GFLOPs\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:49<00:00,  3.28s/it]\n","                 all       1811       3025      0.643      0.462      0.477      0.245\n","                   0       1811        539      0.501      0.607       0.56      0.246\n","                   1       1811        712      0.674      0.802      0.807      0.462\n","                   2       1811        151      0.475      0.269      0.284     0.0865\n","                   3       1811        114      0.505     0.0614      0.146     0.0478\n","                   4       1811        520      0.715      0.577      0.661       0.31\n","                   5       1811          6          1          0    0.00109   0.000685\n","                   6       1811         74      0.463      0.176      0.175     0.0649\n","                   7       1811        162      0.845      0.843      0.885      0.527\n","                   8       1811        747      0.605      0.826      0.775      0.462\n","Results saved to \u001b[1mruns/train/exp3\u001b[0m\n"]}]},{"cell_type":"code","source":["!python train.py --img 640 --batch 64 --epochs 10 --data /content/drive/MyDrive/VienAI/Yolov5/datasets/coco128/data.yaml --weights /content/drive/MyDrive/VienAI/Yolov5/yolov5/runs/train/exp3/weights/last.pt --device 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mG-HdqCAUhep","executionInfo":{"status":"ok","timestamp":1646811585709,"user_tz":-420,"elapsed":4989372,"user":{"displayName":"Tinh Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIkEDM4mLNp9aMlnCQpNdWzDQ15k_zUJE6hLYtLw=s64","userId":"07458451242153991254"}},"outputId":"fa801176-8154-488d-80b6-34699541f085"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/drive/MyDrive/VienAI/Yolov5/yolov5/runs/train/exp3/weights/last.pt, cfg=, data=/content/drive/MyDrive/VienAI/Yolov5/datasets/coco128/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n","YOLOv5 ðŸš€ v6.1-21-ge6e36aa torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     37758  models.yolo.Detect                      [9, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model Summary: 270 layers, 7043902 parameters, 7043902 gradients, 15.9 GFLOPs\n","\n","Transferred 349/349 items from /content/drive/MyDrive/VienAI/Yolov5/yolov5/runs/train/exp3/weights/last.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/datasets/coco128/train/labels.cache' images and labels... 6335 found, 0 missing, 0 empty, 0 corrupt: 100% 6335/6335 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/datasets/coco128/valid/labels.cache' images and labels... 1811 found, 0 missing, 0 empty, 0 corrupt: 100% 1811/1811 [00:00<?, ?it/s]\n","Plotting labels to runs/train/exp4/labels.jpg... \n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.94 anchors/target, 0.990 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp4\u001b[0m\n","Starting training for 10 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       0/9     11.3G   0.03904   0.02086   0.01576       190       640: 100% 99/99 [07:26<00:00,  4.51s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:41<00:00,  2.76s/it]\n","                 all       1811       3025      0.591      0.485       0.48      0.245\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       1/9     11.1G   0.04074   0.02025   0.01622       192       640: 100% 99/99 [07:24<00:00,  4.48s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.72s/it]\n","                 all       1811       3025      0.542      0.483       0.44        0.2\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       2/9     11.1G   0.04177   0.02066   0.01664       176       640: 100% 99/99 [07:24<00:00,  4.49s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.72s/it]\n","                 all       1811       3025      0.479      0.396      0.358      0.157\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       3/9     11.1G   0.04215   0.02158   0.01683       202       640: 100% 99/99 [07:24<00:00,  4.49s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.72s/it]\n","                 all       1811       3025      0.468      0.454       0.39      0.189\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       4/9     11.1G   0.04189   0.02114   0.01634       189       640: 100% 99/99 [07:24<00:00,  4.49s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.72s/it]\n","                 all       1811       3025      0.531      0.443      0.417      0.196\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       5/9     11.1G   0.04136   0.02118   0.01644       189       640: 100% 99/99 [07:25<00:00,  4.50s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.72s/it]\n","                 all       1811       3025      0.521      0.414      0.397      0.195\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       6/9     11.1G   0.03996   0.02094   0.01523       187       640: 100% 99/99 [07:25<00:00,  4.50s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.71s/it]\n","                 all       1811       3025       0.62      0.396      0.421        0.2\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       7/9     11.1G   0.03888   0.02072   0.01435       181       640: 100% 99/99 [07:24<00:00,  4.49s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.71s/it]\n","                 all       1811       3025       0.64      0.458      0.471      0.233\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       8/9     11.1G   0.03825   0.02046   0.01365       161       640: 100% 99/99 [07:25<00:00,  4.50s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.71s/it]\n","                 all       1811       3025       0.62      0.495       0.49      0.243\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       9/9     11.1G   0.03725   0.02018   0.01336       206       640: 100% 99/99 [07:25<00:00,  4.50s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.72s/it]\n","                 all       1811       3025      0.594      0.535      0.507      0.262\n","\n","10 epochs completed in 1.352 hours.\n","Optimizer stripped from runs/train/exp4/weights/last.pt, 14.5MB\n","Optimizer stripped from runs/train/exp4/weights/best.pt, 14.5MB\n","\n","Validating runs/train/exp4/weights/best.pt...\n","Fusing layers... \n","Model Summary: 213 layers, 7034398 parameters, 0 gradients, 15.9 GFLOPs\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:49<00:00,  3.28s/it]\n","                 all       1811       3025      0.594      0.535      0.507      0.262\n","                   0       1811        539       0.47      0.702      0.598      0.255\n","                   1       1811        712      0.617      0.826      0.797      0.456\n","                   2       1811        151      0.405      0.444      0.329      0.101\n","                   3       1811        114      0.346       0.14      0.151     0.0505\n","                   4       1811        520      0.662      0.672       0.69      0.344\n","                   5       1811          6          1          0   0.000466   0.000326\n","                   6       1811         74      0.393      0.311      0.285      0.125\n","                   7       1811        162      0.846       0.87      0.909      0.553\n","                   8       1811        747      0.605      0.849      0.798      0.478\n","Results saved to \u001b[1mruns/train/exp4\u001b[0m\n"]}]},{"cell_type":"code","source":["!python train.py --img 640 --batch 64 --epochs 15 --data /content/drive/MyDrive/VienAI/Yolov5/datasets/coco128/data.yaml --weights /content/drive/MyDrive/VienAI/Yolov5/yolov5/runs/train/exp4/weights/last.pt --device 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1cncYrqHmc_i","executionInfo":{"status":"ok","timestamp":1646819040465,"user_tz":-420,"elapsed":7424928,"user":{"displayName":"Tinh Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIkEDM4mLNp9aMlnCQpNdWzDQ15k_zUJE6hLYtLw=s64","userId":"07458451242153991254"}},"outputId":"a9e44c11-6e2c-4295-c9db-d0e47317a5af"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/drive/MyDrive/VienAI/Yolov5/yolov5/runs/train/exp4/weights/last.pt, cfg=, data=/content/drive/MyDrive/VienAI/Yolov5/datasets/coco128/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=15, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n","YOLOv5 ðŸš€ v6.1-21-ge6e36aa torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     37758  models.yolo.Detect                      [9, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model Summary: 270 layers, 7043902 parameters, 7043902 gradients, 15.9 GFLOPs\n","\n","Transferred 349/349 items from /content/drive/MyDrive/VienAI/Yolov5/yolov5/runs/train/exp4/weights/last.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/datasets/coco128/train/labels.cache' images and labels... 6335 found, 0 missing, 0 empty, 0 corrupt: 100% 6335/6335 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/datasets/coco128/valid/labels.cache' images and labels... 1811 found, 0 missing, 0 empty, 0 corrupt: 100% 1811/1811 [00:00<?, ?it/s]\n","Plotting labels to runs/train/exp5/labels.jpg... \n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.94 anchors/target, 0.990 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp5\u001b[0m\n","Starting training for 15 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      0/14     10.8G   0.03707   0.02019    0.0134       190       640: 100% 99/99 [07:30<00:00,  4.55s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:41<00:00,  2.79s/it]\n","                 all       1811       3025      0.647      0.502      0.517      0.268\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      1/14     11.1G   0.03801   0.01947   0.01277       192       640: 100% 99/99 [07:25<00:00,  4.50s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:41<00:00,  2.74s/it]\n","                 all       1811       3025       0.65      0.467      0.482      0.216\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      2/14     11.2G   0.03875   0.01975   0.01243       176       640: 100% 99/99 [07:25<00:00,  4.50s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:41<00:00,  2.74s/it]\n","                 all       1811       3025      0.556      0.428      0.424      0.206\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      3/14     11.2G   0.04015   0.02105   0.01404       202       640: 100% 99/99 [07:24<00:00,  4.49s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:41<00:00,  2.77s/it]\n","                 all       1811       3025      0.482      0.407      0.359      0.163\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      4/14     11.1G   0.04035   0.02084    0.0144       189       640: 100% 99/99 [07:24<00:00,  4.49s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:41<00:00,  2.74s/it]\n","                 all       1811       3025      0.649      0.414      0.412      0.199\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      5/14     11.1G   0.04041   0.02088   0.01444       189       640: 100% 99/99 [07:24<00:00,  4.49s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.73s/it]\n","                 all       1811       3025      0.547      0.418      0.401       0.18\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      6/14     11.1G   0.03949   0.02082   0.01408       187       640: 100% 99/99 [07:24<00:00,  4.49s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.73s/it]\n","                 all       1811       3025      0.573      0.427      0.397      0.191\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      7/14     11.1G   0.03871   0.02066    0.0136       181       640: 100% 99/99 [07:24<00:00,  4.49s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.72s/it]\n","                 all       1811       3025      0.555      0.484      0.455       0.22\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      8/14     11.1G   0.03855   0.02051   0.01321       161       640: 100% 99/99 [07:25<00:00,  4.50s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.73s/it]\n","                 all       1811       3025      0.617      0.444      0.458      0.224\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      9/14     11.1G   0.03812   0.02038   0.01368       206       640: 100% 99/99 [07:25<00:00,  4.50s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.73s/it]\n","                 all       1811       3025      0.654      0.449      0.482      0.244\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     10/14     11.1G   0.03834   0.02023   0.01422       186       640: 100% 99/99 [07:25<00:00,  4.50s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.73s/it]\n","                 all       1811       3025      0.637      0.452      0.469      0.236\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     11/14     11.1G   0.03772   0.01994   0.01391       202       640: 100% 99/99 [07:25<00:00,  4.50s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.72s/it]\n","                 all       1811       3025      0.539      0.501      0.467      0.241\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     12/14     11.1G    0.0368   0.01993   0.01265       145       640: 100% 99/99 [07:23<00:00,  4.48s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.71s/it]\n","                 all       1811       3025       0.72      0.481       0.52      0.268\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     13/14     11.1G   0.03612   0.01951   0.01226       200       640: 100% 99/99 [07:22<00:00,  4.47s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.71s/it]\n","                 all       1811       3025      0.618       0.52      0.513      0.265\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     14/14     11.1G   0.03555    0.0192   0.01165       188       640: 100% 99/99 [07:21<00:00,  4.46s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.72s/it]\n","                 all       1811       3025      0.669      0.499      0.524      0.277\n","\n","15 epochs completed in 2.029 hours.\n","Optimizer stripped from runs/train/exp5/weights/last.pt, 14.5MB\n","Optimizer stripped from runs/train/exp5/weights/best.pt, 14.5MB\n","\n","Validating runs/train/exp5/weights/best.pt...\n","Fusing layers... \n","Model Summary: 213 layers, 7034398 parameters, 0 gradients, 15.9 GFLOPs\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:48<00:00,  3.25s/it]\n","                 all       1811       3025      0.669      0.499      0.523      0.277\n","                   0       1811        539      0.601       0.59      0.598      0.257\n","                   1       1811        712      0.684      0.803      0.815      0.462\n","                   2       1811        151      0.564      0.311      0.369       0.12\n","                   3       1811        114      0.415      0.175      0.207     0.0694\n","                   4       1811        520      0.742       0.69      0.755      0.385\n","                   5       1811          6          1          0    0.00258    0.00155\n","                   6       1811         74      0.453      0.284      0.243      0.102\n","                   7       1811        162      0.836       0.88       0.92      0.607\n","                   8       1811        747      0.727       0.76      0.797      0.483\n","Results saved to \u001b[1mruns/train/exp5\u001b[0m\n"]}]},{"cell_type":"code","source":["!python train.py --img 640 --batch 64 --epochs 15 --data /content/drive/MyDrive/VienAI/Yolov5/datasets/coco128/data.yaml --weights /content/drive/MyDrive/VienAI/Yolov5/yolov5/runs/train/exp5/weights/last.pt --device 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8s60L1K7F2AX","outputId":"1d3a493e-1ef5-4386-8c2d-08dca03a1b5f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/drive/MyDrive/VienAI/Yolov5/yolov5/runs/train/exp5/weights/last.pt, cfg=, data=/content/drive/MyDrive/VienAI/Yolov5/datasets/coco128/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=15, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n","YOLOv5 ðŸš€ v6.1-21-ge6e36aa torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     37758  models.yolo.Detect                      [9, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model Summary: 270 layers, 7043902 parameters, 7043902 gradients, 15.9 GFLOPs\n","\n","Transferred 349/349 items from /content/drive/MyDrive/VienAI/Yolov5/yolov5/runs/train/exp5/weights/last.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/datasets/coco128/train/labels.cache' images and labels... 6335 found, 0 missing, 0 empty, 0 corrupt: 100% 6335/6335 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/datasets/coco128/valid/labels.cache' images and labels... 1811 found, 0 missing, 0 empty, 0 corrupt: 100% 1811/1811 [00:00<?, ?it/s]\n","Plotting labels to runs/train/exp6/labels.jpg... \n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.94 anchors/target, 0.990 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp6\u001b[0m\n","Starting training for 15 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      0/14     11.3G   0.03511   0.01938   0.01108       190       640: 100% 99/99 [07:25<00:00,  4.50s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:41<00:00,  2.74s/it]\n","                 all       1811       3025      0.652      0.505      0.525      0.276\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      1/14     11.1G   0.03601   0.01875   0.01046       192       640: 100% 99/99 [07:24<00:00,  4.49s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.72s/it]\n","                 all       1811       3025      0.678      0.465      0.504      0.245\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      2/14     11.1G   0.03629   0.01889  0.009858       176       640: 100% 99/99 [07:27<00:00,  4.52s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.72s/it]\n","                 all       1811       3025      0.558      0.429      0.417      0.199\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      3/14     11.1G   0.03793   0.02024   0.01192       202       640: 100% 99/99 [07:29<00:00,  4.54s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 15/15 [00:40<00:00,  2.71s/it]\n","                 all       1811       3025      0.597      0.394      0.406      0.195\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      4/14     11.1G   0.03865   0.02066   0.01221       182       640:  24% 24/99 [01:48<05:39,  4.53s/it]"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/VienAI/Yolov5/datasets/coco128"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JvOHcM0BxZuY","executionInfo":{"status":"ok","timestamp":1646797372483,"user_tz":-420,"elapsed":4,"user":{"displayName":"Tinh Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIkEDM4mLNp9aMlnCQpNdWzDQ15k_zUJE6hLYtLw=s64","userId":"07458451242153991254"}},"outputId":"3319952e-fbfe-487b-d76a-5b2dd0069fc9"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/VienAI/Yolov5/datasets/coco128\n"]}]},{"cell_type":"code","source":["!unzip coco128.zip"],"metadata":{"id":"a7ZpB7vPg5yj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"kHPNKFhwg50d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"ZbiCNOy4g529"},"execution_count":null,"outputs":[]}]}